{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b782f06",
   "metadata": {},
   "source": [
    "# Download raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d293145",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import necessary modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to Python path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "\n",
    "from knowledge_base.src.ingestion.sec_downloader import SECDownloader\n",
    "\n",
    "# Create our downloader instance\n",
    "downloader = SECDownloader()\n",
    "\n",
    "# Test the connection by getting basic company info\n",
    "company_info = downloader.get_company_info('MSTR')\n",
    "print(\"Company Info for MSTR:\")\n",
    "print(company_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62181a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Download and process filings\n",
    "filings = downloader.download_company_filings(\n",
    "    ticker='RDDT',\n",
    "    filing_types=['10-K'],  # Just annual reports\n",
    "    num_filings=2  # Get the most recent filings\n",
    ")\n",
    "\n",
    "print(\"\\nDownloaded Filing Metadata:\")\n",
    "for filing in filings:\n",
    "    print(f\"\\nFiling Type: {filing.get('type')}\")\n",
    "    print(f\"Filing Date: {filing.get('period_of_report', 'N/A')}\")\n",
    "    print(f\"Accession Number: {filing.get('accession_number', 'N/A')}\")\n",
    "    print(f\"File Path: {filing.get('file_path')}\")\n",
    "    \n",
    "    # Get metadata file path\n",
    "    doc_dir = Path(filing['file_path']).parent\n",
    "    metadata_path = doc_dir / \"metadata.json\"\n",
    "    \n",
    "    # Read and display the saved metadata\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "            print(\"\\nStored Metadata:\")\n",
    "            print(json.dumps(metadata, indent=2))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "117b31fd",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Enhanced Metadata Storage for Federated Knowledge Base\n",
    "\n",
    "Each SEC filing is now stored with comprehensive metadata to support integration with multiple knowledge stores:\n",
    "\n",
    "### Storage Location\n",
    "- Metadata is stored as `metadata.json` in the same directory as its raw document\n",
    "- Example path: `data/raw/sec-edgar-filings/AAPL/10-K/0000320193-22-000108/metadata.json`\n",
    "\n",
    "### Metadata Schema\n",
    "\n",
    "1. **Document Identification**\n",
    "   - Unique document ID (SEC accession number)\n",
    "   - Ticker symbol\n",
    "   - Filing type\n",
    "   - Filing date\n",
    "   - Accession number\n",
    "\n",
    "2. **File Information**\n",
    "   - Path to raw document\n",
    "   - Filename\n",
    "   - File size\n",
    "   - Last modified timestamp\n",
    "\n",
    "3. **Company Information**\n",
    "   - Company name\n",
    "   - CIK (Central Index Key)\n",
    "   - Fiscal year end\n",
    "   - Business address\n",
    "\n",
    "4. **Document Metadata**\n",
    "   - Title\n",
    "   - Source (SEC EDGAR)\n",
    "   - Language\n",
    "   - Document type\n",
    "   - Filing period\n",
    "   - Document date\n",
    "\n",
    "5. **Processing Metadata**\n",
    "   - Download timestamp\n",
    "   - Download agent\n",
    "   - Source API\n",
    "   - Schema version\n",
    "\n",
    "6. **Knowledge Base Integration**\n",
    "   - Vector store ID (for semantic search)\n",
    "   - SQL record ID (for structured data)\n",
    "   - Graph node ID (for relationship mapping)\n",
    "   - Related documents\n",
    "   - Searchable tags\n",
    "\n",
    "This enhanced metadata structure supports:\n",
    "- Cross-referencing between different storage systems\n",
    "- Rich document relationships and context\n",
    "- Efficient document retrieval and filtering\n",
    "- Integration with SQL, vector, and graph databases\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Metadata Storage\n",
    "\n",
    "The SEC filing metadata is now stored in JSON files in the `data/raw/metadata` directory. Each metadata file contains:\n",
    "\n",
    "1. Basic filing information:\n",
    "   - Ticker symbol\n",
    "   - Filing type (10-K, 10-Q, etc.)\n",
    "   - Filing date\n",
    "   - File path to the raw document\n",
    "   - Accession number\n",
    "   - File size\n",
    "   - Download timestamp\n",
    "\n",
    "2. Extracted document metadata:\n",
    "   - Company name\n",
    "   - CIK (Central Index Key)\n",
    "   - Fiscal year end\n",
    "   - Period of report\n",
    "   - Business address\n",
    "   - Financial indicators (presence of revenue data, profit data, etc.)\n",
    "\n",
    "The metadata files are named using the pattern: `{ticker}_{type}_{date}_metadata.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce4585",
   "metadata": {},
   "source": [
    "# Process Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7054a2",
   "metadata": {},
   "source": [
    "## Processing for SQL Database data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2efcaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Current working directory: /Users/daylight/Desktop/Financial Insight AI/notebooks\n",
      "Project root: /Users/daylight/Desktop/Financial Insight AI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 17:39:18,215 - knowledge_base.src.storage.sql_store - INFO - Created SQL engine: sqlite:////Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/financial_kb.db\n",
      "2025-08-03 17:39:18,217 - knowledge_base.src.storage.sql_store - INFO - Created SQL tables\n",
      "2025-08-03 17:39:18,387 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloading 10-K filings for AAPL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL ['10-K'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 17:39:18,702 - knowledge_base.src.ingestion.sec_downloader - INFO - Company fiscal year end: 20XX-09-27 (from code: 0927)\n",
      "2025-08-03 17:39:18,707 - knowledge_base.src.ingestion.sec_downloader - INFO - Available fields in filings: ['accessionNumber', 'filingDate', 'reportDate', 'acceptanceDateTime', 'act', 'form', 'fileNumber', 'filmNumber', 'items', 'core_type', 'size', 'isXBRL', 'isInlineXBRL', 'primaryDocument', 'primaryDocDescription']\n",
      "2025-08-03 17:39:18,708 - knowledge_base.src.ingestion.sec_downloader - WARNING - fiscalYearEnd field not found in filings data\n",
      "2025-08-03 17:39:18,708 - knowledge_base.src.ingestion.sec_downloader - INFO - form (first 3 entries): ['10-Q', '8-K', 'SCHEDULE 13G/A']\n",
      "2025-08-03 17:39:18,709 - knowledge_base.src.ingestion.sec_downloader - INFO - reportDate (first 3 entries): ['2025-06-28', '2025-07-31', '']\n",
      "2025-08-03 17:39:18,709 - knowledge_base.src.ingestion.sec_downloader - INFO - accessionNumber (first 3 entries): ['0000320193-25-000073', '0000320193-25-000071', '0000932471-25-000778']\n",
      "2025-08-03 17:39:18,710 - knowledge_base.src.ingestion.sec_downloader - WARNING - Field 'fiscalYearEnd' not found in filings data\n",
      "2025-08-03 17:39:19,108 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded full-submission.txt\n",
      "2025-08-03 17:39:19,226 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 000032019324000123.html\n",
      "2025-08-03 17:39:19,229 - knowledge_base.src.ingestion.sec_downloader - INFO - Using actual fiscal year end: 2024-09-27\n",
      "2025-08-03 17:39:19,594 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded full-submission.txt\n",
      "2025-08-03 17:39:19,710 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 000032019323000106.html\n",
      "2025-08-03 17:39:19,712 - knowledge_base.src.ingestion.sec_downloader - INFO - Using actual fiscal year end: 2023-09-27\n",
      "2025-08-03 17:39:20,076 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded full-submission.txt\n",
      "2025-08-03 17:39:20,199 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 000032019322000108.html\n",
      "2025-08-03 17:39:20,201 - knowledge_base.src.ingestion.sec_downloader - INFO - Using actual fiscal year end: 2022-09-27\n",
      "2025-08-03 17:39:20,598 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded full-submission.txt\n",
      "2025-08-03 17:39:20,724 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 000032019321000105.html\n",
      "2025-08-03 17:39:20,726 - knowledge_base.src.ingestion.sec_downloader - INFO - Using actual fiscal year end: 2021-09-27\n",
      "2025-08-03 17:39:21,191 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded full-submission.txt\n",
      "2025-08-03 17:39:21,312 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 000032019320000096.html\n",
      "2025-08-03 17:39:21,315 - knowledge_base.src.ingestion.sec_downloader - INFO - Using actual fiscal year end: 2020-09-27\n",
      "2025-08-03 17:39:21,320 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 5 10-K filings for AAPL\n",
      "2025-08-03 17:39:21,328 - knowledge_base.src.storage.sql_store - INFO - Added/updated client: AAPL\n",
      "2025-08-03 17:39:21,334 - knowledge_base.src.storage.sql_store - INFO - Added document: 0000320193-24-000123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(filings) 5\n",
      "if filings called\n",
      "filing {'ticker': 'AAPL', 'type': '10-K', 'file_path': '/Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/AAPL/10-K/000032019324000123/full-submission.txt', 'date': '2024-09-28', 'downloaded_at': '2025-08-03T17:39:19.229524', 'file_size': 9759333, 'accession_number': '0000320193-24-000123', 'period_of_report': '2024-09-28', 'company_name': 'Apple Inc.', 'cik': '0000320193', 'fiscal_year_end': '2024-09-27', 'business_address': '', 'has_revenue_data': True, 'has_profit_data': True, 'has_balance_sheet': True, 'has_cash_flow': True, 'financial_keywords_count': 0, 'metadata_path': '/Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/AAPL/10-K/000032019324000123/metadata.json'}\n",
      "IF document_id CALLED\n",
      "Processing HTML file: /Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/AAPL/10-K/000032019324000123/000032019324000123.html\n",
      "Processing 000032019324000123.html for AAPL\n",
      "Original text length: 10406 characters\n",
      "Cleaned text length: 3662 characters\n",
      "Extracted 0 metrics from text\n",
      "Extracted 0 metrics\n",
      "\n",
      "Validation results: {}\n",
      "\n",
      "Comparative metrics: {'AAPL': {}, 'MSFT': {}, 'GOOGL': {}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEST_TICKER = 'AAPL'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from knowledge_base.src.ingestion.sec_downloader import SECDownloader\n",
    "from knowledge_base.src.ingestion.sec_sql_extractor import SECDataExtractor\n",
    "from knowledge_base.src.storage.sql_manager import FinancialMetricsManager\n",
    "\n",
    "\n",
    "# Force reload the updated module\n",
    "import importlib\n",
    "import knowledge_base.src.ingestion.sql_extractor\n",
    "importlib.reload(knowledge_base.src.ingestion.sec_downloader)\n",
    "importlib.reload(knowledge_base.src.ingestion.sql_extractor)\n",
    "importlib.reload(knowledge_base.src.storage.sql_manager)\n",
    "\n",
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Project root: {Path.cwd().parent}\")\n",
    "\n",
    "# Then import the extractor\n",
    "from knowledge_base.src.ingestion.sql_extractor import SECDataExtractor\n",
    "\n",
    "# Initialize components\n",
    "downloader = SECDownloader()\n",
    "extractor = SECDataExtractor()\n",
    "sql_manager = FinancialMetricsManager()\n",
    "\n",
    "# Step 1: Download SEC filing\n",
    "filings = downloader.download_company_filings(\n",
    "    ticker=TEST_TICKER,\n",
    "    filing_types=['10-K'],\n",
    "    num_filings=5\n",
    ")\n",
    "\n",
    "print(\"len(filings)\", len(filings))\n",
    "\n",
    "# Step 2: Process the filing\n",
    "if filings:\n",
    "\n",
    "    print(\"if filings called\")\n",
    "    \n",
    "    filing = filings[0]\n",
    "    print(\"filing\", filing)\n",
    "    file_dir = Path(filing['file_path']).parent\n",
    "    \n",
    "    # Look for XBRL or HTML version\n",
    "    xbrl_file = next(file_dir.glob(\"*.xml\"), None)\n",
    "    html_file = next(file_dir.glob(\"*.htm*\"), None)\n",
    "\n",
    "\n",
    "    # Add client to the database before adding the document\n",
    "    client_data = {\n",
    "        \"id\": filing['ticker'],\n",
    "        \"company_name\": filing.get('company_name', ''),\n",
    "        \"cik\": filing.get('cik', ''),\n",
    "        \"industry\": \"\",  # Fill if available\n",
    "        \"sector\": \"\",    # Fill if available\n",
    "        \"market_cap\": None  # Fill if available\n",
    "    }\n",
    "    sql_manager.sql_store.add_client(client_data)\n",
    "    \n",
    "    # Create document in SQL store first\n",
    "    doc_data = {\n",
    "        \"document_id\": filing['accession_number'],\n",
    "        \"client_id\": filing['ticker'],\n",
    "        \"filing_type\": filing['type'],\n",
    "        \"filing_date\": filing['period_of_report'],\n",
    "        \"file_path\": filing['file_path'],\n",
    "        \"file_size\": filing['file_size'],\n",
    "        \"download_date\": datetime.fromisoformat(filing['downloaded_at']),\n",
    "        \"has_revenue_data\": filing['has_revenue_data'],\n",
    "        \"has_profit_data\": filing['has_profit_data'],\n",
    "        \"has_balance_sheet\": filing['has_balance_sheet'],\n",
    "        \"has_cash_flow\": filing['has_cash_flow']\n",
    "    }\n",
    "    \n",
    "    # Add document to get SQL document_id\n",
    "    document_id = sql_manager.sql_store.add_document(doc_data)\n",
    "    \n",
    "    if document_id:\n",
    "\n",
    "        print(\"IF document_id CALLED\")\n",
    "\n",
    "        # Try XBRL first, then HTML, then full submission\n",
    "        if xbrl_file:\n",
    "            print(f\"Processing XBRL file: {xbrl_file}\")\n",
    "            metrics = extractor.process_document(str(xbrl_file), TEST_TICKER)\n",
    "        elif html_file:\n",
    "            print(f\"Processing HTML file: {html_file}\")\n",
    "            metrics = extractor.process_document(str(html_file), TEST_TICKER)\n",
    "        else:\n",
    "            print(f\"Processing full submission: {filing['file_path']}\")\n",
    "            metrics = extractor.process_document(filing['file_path'], TEST_TICKER)\n",
    "            \n",
    "        print(f\"Extracted {len(metrics)} metrics\")\n",
    "        if metrics:\n",
    "            sql_manager.save_extracted_metrics(metrics, document_id)\n",
    "            print(\"Metrics saved to database\")\n",
    "            print(\"metrics\", metrics)\n",
    "\n",
    "        # Validate the extractions\n",
    "        validation = sql_manager.validate_client_metrics(TEST_TICKER, 2024)\n",
    "        print(\"\\nValidation results:\", validation)\n",
    "\n",
    "        # Get comparative metrics\n",
    "        comparative = sql_manager.get_comparative_metrics(\n",
    "            [\"AAPL\", \"MSFT\", \"GOOGL\"],\n",
    "            [\"revenue\", \"net_income\"],\n",
    "            2024\n",
    "        )\n",
    "        print(\"\\nComparative metrics:\", comparative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c8f1a",
   "metadata": {},
   "source": [
    "## Quick test for SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57287db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "============================================================\n",
      "DETAILED DATABASE ANALYSIS\n",
      "============================================================\n",
      "Tables found: ['clients', 'documents', 'document_chunks', 'financial_metrics']\n",
      "\n",
      "--- CLIENTS TABLE ---\n",
      "Columns: ['id', 'company_name', 'cik', 'industry', 'sector', 'market_cap', 'created_date', 'last_updated']\n",
      "Records: 2\n",
      "Sample data:\n",
      "  id company_name        cik industry sector market_cap               created_date               last_updated\n",
      "RDDT Reddit, Inc. 0001713445                       None 2025-08-03 23:38:20.957135 2025-08-03 23:38:20.957139\n",
      "AAPL   Apple Inc. 0000320193                       None 2025-08-03 23:39:21.326800 2025-08-03 23:39:21.326803\n",
      "\n",
      "--- DOCUMENTS TABLE ---\n",
      "Columns: ['document_pk', 'document_id', 'client_id', 'filing_type', 'filing_date', 'period_of_report', 'fiscal_year_end', 'file_path', 'file_size', 'download_date', 'processed_date', 'total_chunks', 'financial_density', 'has_revenue_data', 'has_profit_data', 'has_balance_sheet', 'has_cash_flow', 'metadata_json']\n",
      "Records: 3\n",
      "Sample data:\n",
      " document_pk          document_id client_id filing_type filing_date period_of_report fiscal_year_end                                                                                                             file_path  file_size              download_date             processed_date  total_chunks  financial_density  has_revenue_data  has_profit_data  has_balance_sheet  has_cash_flow metadata_json\n",
      "           1 0000950170-25-061046      MSFT        10-Q  2025-03-31             None            None /Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/MSFT/10-Q/000095017025061046/full-submission.txt   29845298 2025-08-03 17:35:50.485629                       None             0                0.0                 1                1                  1              1          None\n",
      "           2 0001713445-25-000196      RDDT        10-Q  2025-06-30             None            None /Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/RDDT/10-Q/000171344525000196/full-submission.txt    8920364 2025-08-03 17:38:20.912482 2025-08-03 23:38:20.961296             0                0.0                 1                1                  1              1          None\n",
      "           3 0000320193-24-000123      AAPL        10-K  2024-09-28             None            None /Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/AAPL/10-K/000032019324000123/full-submission.txt    9759333 2025-08-03 17:39:19.229524                       None             0                0.0                 1                1                  1              1          None\n",
      "\n",
      "--- DOCUMENT_CHUNKS TABLE ---\n",
      "Columns: ['id', 'document_pk', 'chunk_index', 'section', 'content_type', 'chunk_size', 'financial_density', 'contains_numbers', 'contains_financial_terms', 'key_topics', 'vector_id']\n",
      "Records: 0\n",
      "(No data)\n",
      "\n",
      "--- FINANCIAL_METRICS TABLE ---\n",
      "Columns: ['id', 'client_id', 'document_pk', 'metric_name', 'metric_value', 'metric_unit', 'period_type', 'period_end_date', 'fiscal_year', 'fiscal_quarter', 'source_section', 'extraction_confidence', 'extraction_method', 'context_text', 'metadata_json', 'created_date']\n",
      "Records: 210\n",
      "Sample data:\n",
      " id client_id  document_pk metric_name  metric_value metric_unit period_type period_end_date  fiscal_year fiscal_quarter          source_section  extraction_confidence extraction_method                                                                                                                                                                                             context_text                                                                                                                                    metadata_json               created_date\n",
      "  1      MSFT            1     revenue       70066.0         USD      annual  unknown_period         2025           None 000095017025061046.html                   0.70        text_regex                                                                                                                                                                                        Revenue $ 70,066  {\"source_document\": \"000095017025061046.html\", \"extraction_timestamp\": \"2025-08-03T17:35:50.509257\", \"original_period_format\": \"unknown_period\"} 2025-08-03 23:35:50.511999\n",
      "  2      MSFT            1     revenue       70066.0         USD      annual  unknown_period         2025           None 000095017025061046.html                   0.70        text_regex                                                                                                                                                                                        Revenue $ 70,066  {\"source_document\": \"000095017025061046.html\", \"extraction_timestamp\": \"2025-08-03T17:35:50.511029\", \"original_period_format\": \"unknown_period\"} 2025-08-03 23:35:50.512000\n",
      "  3      RDDT            2     revenue      524147.0                  annual                         2025           None 000171344525000196.html                   0.95              xbrl <ix:nonFraction contextRef=\"c-215\" decimals=\"-3\" format=\"ixt:num-dot-decimal\" id=\"f-892\" name=\"us-gaap:RevenueFromContractWithCustomerExcludingAssessedTax\" scale=\"3\" unitRef=\"usd\">524,147</ix:nonFract               {\"source_document\": \"000171344525000196.html\", \"extraction_timestamp\": \"2025-08-03T17:38:21.324703\", \"original_period_format\": \"\"} 2025-08-03 23:36:25.580352\n",
      "\n",
      "=== ADDITIONAL ANALYSIS ===\n",
      "Financial metrics extracted: 210\n",
      "Clients registered: 2\n",
      "\n",
      "Document processing status:\n",
      "client_id filing_type filing_date  has_revenue_data  has_profit_data  has_balance_sheet  has_cash_flow  financial_density\n",
      "     MSFT        10-Q  2025-03-31                 1                1                  1              1                0.0\n",
      "     RDDT        10-Q  2025-06-30                 1                1                  1              1                0.0\n",
      "     AAPL        10-K  2024-09-28                 1                1                  1              1                0.0\n",
      "Document chunks created: 0\n",
      "\n",
      "✅ Database analysis complete!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Simple SQL Database Test\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Import necessary modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# # Add the project root to Python path so we can import our modules\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Force reload the updated module\n",
    "import importlib\n",
    "import knowledge_base.src.ingestion.sql_extractor\n",
    "importlib.reload(knowledge_base.src.ingestion.sec_downloader)\n",
    "importlib.reload(knowledge_base.src.ingestion.sql_extractor)\n",
    "importlib.reload(knowledge_base.src.storage.sql_manager)\n",
    "\n",
    "\n",
    "\n",
    "# # Database path\n",
    "db_path = Path(\"../knowledge_base/data/financial_kb.db\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED DATABASE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Connect to database for detailed analysis\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "try:\n",
    "    # Get all tables\n",
    "    tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "    print(f\"Tables found: {tables['name'].tolist()}\")\n",
    "    \n",
    "    # Analyze each table\n",
    "    for table_name in tables['name']:\n",
    "        print(f\"\\n--- {table_name.upper()} TABLE ---\")\n",
    "        \n",
    "        # Get table schema\n",
    "        schema = pd.read_sql_query(f\"PRAGMA table_info({table_name})\", conn)\n",
    "        print(f\"Columns: {schema['name'].tolist()}\")\n",
    "        \n",
    "        # Get record count\n",
    "        count = pd.read_sql_query(f\"SELECT COUNT(*) as count FROM {table_name}\", conn)\n",
    "        record_count = count['count'].iloc[0]\n",
    "        print(f\"Records: {record_count}\")\n",
    "        \n",
    "        # Show sample data if records exist\n",
    "        if record_count > 0:\n",
    "            sample = pd.read_sql_query(f\"SELECT * FROM {table_name} LIMIT 3\", conn)\n",
    "            print(\"Sample data:\")\n",
    "            print(sample.to_string(index=False))\n",
    "        else:\n",
    "            print(\"(No data)\")\n",
    "    \n",
    "    # Additional analysis\n",
    "    print(f\"\\n=== ADDITIONAL ANALYSIS ===\")\n",
    "    \n",
    "    # Check for any financial metrics\n",
    "    metrics_count = pd.read_sql_query(\"SELECT COUNT(*) as count FROM financial_metrics\", conn)['count'].iloc[0]\n",
    "    print(f\"Financial metrics extracted: {metrics_count}\")\n",
    "    \n",
    "    # Check for any clients\n",
    "    clients_count = pd.read_sql_query(\"SELECT COUNT(*) as count FROM clients\", conn)['count'].iloc[0]\n",
    "    print(f\"Clients registered: {clients_count}\")\n",
    "    \n",
    "    # Check document processing status\n",
    "    docs = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            client_id,\n",
    "            filing_type,\n",
    "            filing_date,\n",
    "            has_revenue_data,\n",
    "            has_profit_data,\n",
    "            has_balance_sheet,\n",
    "            has_cash_flow,\n",
    "            financial_density\n",
    "        FROM documents\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    if not docs.empty:\n",
    "        print(f\"\\nDocument processing status:\")\n",
    "        print(docs.to_string(index=False))\n",
    "    \n",
    "    # Check for any chunks\n",
    "    chunks_count = pd.read_sql_query(\"SELECT COUNT(*) as count FROM document_chunks\", conn)['count'].iloc[0]\n",
    "    print(f\"Document chunks created: {chunks_count}\")\n",
    "    \n",
    "    print(f\"\\n✅ Database analysis complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error analyzing database: {e}\")\n",
    "\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ca72e",
   "metadata": {},
   "source": [
    "## Processing for Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1d8985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 16:43:14,721 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloading 10-K filings for NVDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA ['10-K'] 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 16:43:14,909 - knowledge_base.src.ingestion.sec_downloader - INFO - Company fiscal year end: 20XX-01-25 (from code: 0125)\n",
      "2025-08-03 16:43:14,912 - knowledge_base.src.ingestion.sec_downloader - INFO - Available fields in filings: ['accessionNumber', 'filingDate', 'reportDate', 'acceptanceDateTime', 'act', 'form', 'fileNumber', 'filmNumber', 'items', 'core_type', 'size', 'isXBRL', 'isInlineXBRL', 'primaryDocument', 'primaryDocDescription']\n",
      "2025-08-03 16:43:14,913 - knowledge_base.src.ingestion.sec_downloader - WARNING - fiscalYearEnd field not found in filings data\n",
      "2025-08-03 16:43:14,913 - knowledge_base.src.ingestion.sec_downloader - INFO - form (first 3 entries): ['144', '4', '144']\n",
      "2025-08-03 16:43:14,913 - knowledge_base.src.ingestion.sec_downloader - INFO - reportDate (first 3 entries): ['', '2025-07-29', '']\n",
      "2025-08-03 16:43:14,914 - knowledge_base.src.ingestion.sec_downloader - INFO - accessionNumber (first 3 entries): ['0001921094-25-000860', '0001197649-25-000017', '0001921094-25-000852']\n",
      "2025-08-03 16:43:14,914 - knowledge_base.src.ingestion.sec_downloader - WARNING - Field 'fiscalYearEnd' not found in filings data\n",
      "2025-08-03 16:43:15,329 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded full-submission.txt\n",
      "2025-08-03 16:43:15,557 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 000104581025000023.html\n",
      "2025-08-03 16:43:15,560 - knowledge_base.src.ingestion.sec_downloader - INFO - Using actual fiscal year end: 2025-01-25\n",
      "2025-08-03 16:43:15,567 - knowledge_base.src.ingestion.sec_downloader - INFO - Downloaded 1 10-K filings for NVDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded 1 filings\n",
      "\n",
      "Processing 10-K filing from /Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/NVDA/10-K/000104581025000023/full-submission.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 16:43:16,645 - knowledge_base.src.ingestion.document_processor - INFO - Processed /Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/NVDA/10-K/000104581025000023/full-submission.txt: 1437 chunks created\n",
      "2025-08-03 16:43:16,670 - knowledge_base.src.ingestion.document_processor - INFO - Saved 1437 chunks to /Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/processed/NVDA_10-K_2025-01-26_processed.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed chunks to: NVDA_10-K_2025-01-26_processed.json\n",
      "\n",
      "Total chunks generated: 1437\n",
      "\n",
      "Sample chunk content:\n",
      "Part IIItem 5. Market for Registrant's Common Equity, Related Stockholder Matters and Issuer Purchases of Equity SecuritiesOur common stock is traded on the Nasdaq Global Select Market under the symbol NVDA. Public trading of our common stock began on January 22, 1999. Prior to that, there was no public market for our common stock. As of February 21, 2025, we had approximately 842 registered shareholders, not including those shares held in street or nominee name. In May 2024, we announced a ten-\n",
      "\n",
      "Sample chunk metadata:\n",
      "{'ticker': 'NVDA', 'type': '10-K', 'file_path': '/Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/NVDA/10-K/000104581025000023/full-submission.txt', 'date': '2025-01-26', 'downloaded_at': '2025-08-03T16:43:15.561126', 'file_size': 12325809, 'accession_number': '0001045810-25-000023', 'period_of_report': '2025-01-26', 'company_name': 'NVIDIA CORP', 'cik': '0001045810', 'fiscal_year_end': '2025-01-25', 'business_address': '', 'has_revenue_data': True, 'has_profit_data': True, 'has_balance_sheet': True, 'has_cash_flow': True, 'financial_keywords_count': 0, 'metadata_path': '/Users/daylight/Desktop/Financial Insight AI/knowledge_base/data/raw/NVDA/10-K/000104581025000023/metadata.json', 'source': 'SEC Edgar', 'processed_at': '2025-08-03T16:43:15.572150', 'section': 'SEC Part: Part III', 'chunk_index': 0, 'chunk_size': 996, 'processed_date': '2025-08-03T16:43:16.418172', 'content_type': 'general', 'financial_density': 1.2269938650306749, 'contains_numbers': False, 'contains_financial_terms': True, 'key_topics': []}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from knowledge_base.src.ingestion.document_processor import FinancialDocumentProcessor\n",
    "from knowledge_base.src.ingestion.sec_downloader import SECDownloader\n",
    "from knowledge_base.config.settings import get_settings\n",
    "\n",
    "# Initialize settings and components\n",
    "settings = get_settings()\n",
    "processor = FinancialDocumentProcessor()\n",
    "downloader = SECDownloader()\n",
    "\n",
    "# Define test parameters\n",
    "TEST_TICKER = \"NVDA\"  # Example: NVIDIA\n",
    "TEST_FILING_TYPES = [\"10-K\"]  # Or include \"8-K\", \"10-Q\"\n",
    "TEST_OUTPUT_DIR = Path(settings.data.processed_data_path)\n",
    "TEST_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Step 1: Download filings\n",
    "downloaded_filings = downloader.download_company_filings(\n",
    "    ticker=TEST_TICKER,\n",
    "    filing_types=TEST_FILING_TYPES,\n",
    "    num_filings=1  # Just get the most recent one\n",
    ")\n",
    "print(f\"\\nDownloaded {len(downloaded_filings)} filings\")\n",
    "\n",
    "# Step 2: Process each filing\n",
    "all_processed_chunks = []\n",
    "for filing in downloaded_filings:\n",
    "    print(f\"\\nProcessing {filing['type']} filing from {filing['file_path']}\")\n",
    "    \n",
    "    # Add processing metadata\n",
    "    filing['source'] = 'SEC Edgar'\n",
    "    filing['processed_at'] = datetime.now().isoformat()\n",
    "    \n",
    "    # Process the filing\n",
    "    chunks = processor.process_sec_filing(\n",
    "        file_path=filing['file_path'],\n",
    "        metadata=filing\n",
    "    )\n",
    "    all_processed_chunks.extend(chunks)\n",
    "    \n",
    "    # Save processed chunks\n",
    "    output_file = f\"{TEST_TICKER}_{filing['type']}_{filing['date']}_processed.json\"\n",
    "    processor.save_processed_chunks(chunks, output_file)\n",
    "    print(f\"Saved processed chunks to: {output_file}\")\n",
    "\n",
    "# Step 3: Inspect results\n",
    "print(f\"\\nTotal chunks generated: {len(all_processed_chunks)}\")\n",
    "if all_processed_chunks:\n",
    "    print(\"\\nSample chunk content:\")\n",
    "    print(all_processed_chunks[0].page_content[:500])\n",
    "    print(\"\\nSample chunk metadata:\")\n",
    "    print(all_processed_chunks[0].metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
